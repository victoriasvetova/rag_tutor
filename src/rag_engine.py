from langchain_ollama import ChatOllama
from langchain.prompts import ChatPromptTemplate
from src.database import VectorDatabase
from src.config import settings
from loguru import logger


class RAGEngine:
    def __init__(self):
        self.db = VectorDatabase()

        self.llm = ChatOllama(
            base_url=settings.OLLAMA_BASE_URL,
            model=settings.LLM_MODEL,
            temperature=0.3
        )

        # üéì PROMPT –†–ï–ü–ï–¢–ò–¢–û–†–ê
        self.prompt_template = ChatPromptTemplate.from_template("""
–¢—ã ‚Äî AI-—Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞–º.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –ü–æ–Ω—è—Ç–Ω–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ –æ–±—ä—è—Å–Ω–∏—Ç—å —Ç–µ–º—É
2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¢–û–õ–¨–ö–û –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
3. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ–ø–æ–ª–Ω—ã–π ‚Äî –æ–±—ä—è—Å–Ω–∏ –±–∞–∑–æ–≤—ã–µ –ø–æ–Ω—è—Ç–∏—è
4. –ü—Ä–∏–≤–æ–¥–∏ –ø—Ä–∏–º–µ—Ä—ã, –µ—Å–ª–∏ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ

–ü–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è:
- –∑–∞–¥–∞–π 2 –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏
- –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–π, —á—Ç–æ –∏–∑—É—á–∏—Ç—å –¥–∞–ª—å—à–µ

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
----------------
{context}
----------------

–í–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞:
{question}

–û—Ç–≤–µ—Ç (–Ω–∞ —Ä—É—Å—Å–∫–æ–º, —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–æ):
""")

    def get_answer(self, query: str):
        logger.info(f"üîç –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}")

        # 1Ô∏è‚É£ RETRIEVAL: –±–µ—Ä—ë–º –ë–û–õ–¨–®–ï –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        docs_with_scores = self.db.search_with_score(
            query,
            k=settings.TOP_K_RETRIEVAL
        )

        if not docs_with_scores:
            return (
                "–Ø –Ω–µ –Ω–∞—à—ë–ª —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –≤ –±–∞–∑–µ, –Ω–æ –¥–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º —Ç–µ–º—É –ø–æ—à–∞–≥–æ–≤–æ.",
                {}
            )

        # 2Ô∏è‚É£ –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        docs_with_scores.sort(key=lambda x: x[1])

        # 3Ô∏è‚É£ –ë–µ—Ä—ë–º TOP_N –±–µ–∑ –∂—ë—Å—Ç–∫–∏—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤
        selected_docs = docs_with_scores[:settings.TOP_N_RERANK]

        docs = [doc for doc, _ in selected_docs]

        # 4Ô∏è‚É£ –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—É—á–∞—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_text = "\n\n".join(doc.page_content for doc in docs)

        # 5Ô∏è‚É£ –ò—Å—Ç–æ—á–Ω–∏–∫–∏ (–ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å)
        sources = {
            doc.metadata["source"]: doc.metadata["title"]
            for doc in docs
        }

        logger.info("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—É—á–∞—é—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞...")

        chain = self.prompt_template | self.llm
        response = chain.invoke({
            "context": context_text,
            "question": query
        })

        return response.content.strip(), sources